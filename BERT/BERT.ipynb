{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5c225d-637d-42bb-b4a9-098bd27cb486",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-22 04:09:17--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-02-22 04:09:17 (146 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf443f0c-36e2-4ec0-b591-897d434a881e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your notebook's working directory is set such that ../llm-tokenizer is reachable:\n",
    "tokenizer_dir = os.path.abspath(os.path.join(os.getcwd(), '../llm-tokenizer'))\n",
    "if tokenizer_dir not in sys.path:\n",
    "    sys.path.insert(0, tokenizer_dir)\n",
    "\n",
    "import BPETokenizer  # Now you should be able to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22820cf2-f6be-4a2b-84cb-d7dc0cd42490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device index: 0\n",
      "Running on GPU: NVIDIA RTX A6000\n",
      "GPU properties:\n",
      "  - Compute Capability: 8.6\n",
      "  - Total Memory: 47.54 GB\n",
      "  - Multiprocessor Count: 84\n",
      "  - Max Threads per Multiprocessor: 1536\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    device_props = torch.cuda.get_device_properties(current_device)\n",
    "    memory_summary = torch.cuda.memory_summary(device=current_device, abbreviated=True)\n",
    "    \n",
    "    print(\"Current device index:\", current_device)\n",
    "    print(\"Running on GPU:\", device_name)\n",
    "    print(\"GPU properties:\")\n",
    "    print(\"  - Compute Capability:\", f\"{device_props.major}.{device_props.minor}\")\n",
    "    print(\"  - Total Memory:\", f\"{device_props.total_memory / (1024**3):.2f} GB\")\n",
    "    print(\"  - Multiprocessor Count:\", device_props.multi_processor_count)\n",
    "    print(\"  - Max Threads per Multiprocessor:\", device_props.max_threads_per_multi_processor)\n",
    "else:\n",
    "    print(\"CUDA is not available, running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacea303-4d3d-429d-b2ab-bf2debdb5218",
   "metadata": {},
   "source": [
    "# Pretraining Data - GPT Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f9b04823-54d4-47dd-a2f3-fc99240d0f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"next token prediction DataLoader used for GPT like models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        len(text)\n",
    "\n",
    "        self.tokenizer = BPETokenizer.Tokenizer(text, encoding_vocab_size=2000, raw_tokens=False)\n",
    "        self.tokenizer.load_from_file()\n",
    "        encoded_dataset = self.tokenizer.encode(text, raw_tokens=False)\n",
    "        print(f\"max vocabulary size={max(encoded_dataset)}, compression ratio={len(encoded_dataset) / len(text)}\")\n",
    "        split = int(len(encoded_dataset) * 0.80)\n",
    "        self.train_data =  torch.tensor(encoded_dataset[:split])\n",
    "        self.val_data = torch.tensor(encoded_dataset[split+config.block_size:])\n",
    "        print(f\"train_data.shape={self.train_data.shape}, val_data.shape={self.val_data.shape}\")\n",
    "        \n",
    "        self.train_data_ix = 0\n",
    "        self.val_data_ix = 0\n",
    "        self.batch_step = self.config.batch_size * self.config.block_size \n",
    "        \n",
    "    def next_batch(self, mode=\"train\", device=device):\n",
    "        \"\"\" mode=[\"train\", \"eval\"] \"\"\"\n",
    "        if mode == \"train\":\n",
    "            x, y = self._next_batch_train()\n",
    "        else:\n",
    "            x, y = self._next_batch_eval()\n",
    "        if device:\n",
    "            return x.to(device), y.to(device)\n",
    "        return x, y\n",
    "    \n",
    "    def _next_batch_train(self):\n",
    "        \n",
    "        data = self.train_data\n",
    "        ix = int(random() * (len(data) - 2*self.batch_step))\n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.train_data_ix += self.batch_step \n",
    "        if self.train_data_ix + self.batch_step + 1 > len(self.train_data):\n",
    "            self.train_data_ix = 0\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def _next_batch_eval(self):\n",
    "        \n",
    "        data = self.train_data\n",
    "        ix = int(random() * (len(data) - 2*self.batch_step))\n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.val_data_ix += self.batch_step \n",
    "        if self.val_data_ix + self.batch_step + 1 > len(self.val_data):\n",
    "            self.val_data_ix = 0\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "72adc4f3-2640-4a05-9969-079806cbcb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BERTConfig:\n",
    "    BERT_batch_size = 6\n",
    "    batch_size = BERT_batch_size * 2\n",
    "    block_size = 5\n",
    "    \n",
    "config = BERTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "83c2b8ed-11e0-485e-9bcc-b28bcd8a0471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocabulary size=2213, compression ratio=0.4458684554516162\n",
      "train_data.shape=torch.Size([397855]), val_data.shape=torch.Size([99459])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(config)\n",
    "x, y = data_loader.next_batch(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "79332896-fd09-4b61-999b-932d87e2beb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 5]), torch.Size([12, 5]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0436274-8a8b-4ff6-bb04-061f1d89e734",
   "metadata": {},
   "source": [
    "# Pretraining Data - BERT Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "364c0fdd-5ba2-4b1b-a4c6-8b727c14a2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataLoader(DataLoader):\n",
    "    \"\"\"data loader for BERT-like MLM + NSP loss\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.max_vocab_size = max(self.tokenizer.encoding_map.values())\n",
    "        self.CLS =self.max_vocab_size + 1\n",
    "        self.SEP = self.CLS + 1\n",
    "        self.MASK = self.SEP + 1\n",
    "        print(f\"new tokens: {self.max_vocab_size}, {self.CLS}, {self.SEP}, {self.MASK}\")\n",
    "        \n",
    "    def next_batch(self, device=device, test=False):\n",
    "        _x, _ = super().next_batch(device=None)\n",
    "        x, y_MLM, y_NSP = [], [], []\n",
    "        assert len(_x) % 2 == 0, \"BERTDataLoader batch size should be % 2 == 0\"\n",
    "        for ix in range(int(len(_x) / 2)): \n",
    "            x0 = _x[ix].clone()\n",
    "            if random() < 0.5:\n",
    "                x1 = _x[ix+1].clone()\n",
    "                y_NSP.append(torch.tensor(1))\n",
    "            else:\n",
    "                __x, _ = super().next_batch(device=None)\n",
    "                x1 = __x[0].clone()\n",
    "                y_NSP.append(torch.tensor(0))\n",
    "            y_MLM.append(self._make_input(x0, x1))\n",
    "            x.append(self._make_input(self._mask(x0), self._mask(x1)))\n",
    "            \n",
    "        if test:\n",
    "            for i, xx in enumerate(x):\n",
    "                if y_NSP[i] == 1:\n",
    "                    a, b = y_MLM[i][1:1+BERTConfig.block_size], _x[i]\n",
    "                    assert (a == b).all(), (a, b)\n",
    "                    a, b = y_MLM[i][1+BERTConfig.block_size+1:1+2*BERTConfig.block_size+1], _x[i+1]\n",
    "                    assert (a == b).all(), (a, b)\n",
    "                    print(f\"{i} TEST PASSED same sentence\")\n",
    "            \n",
    "        return torch.stack(x).to(device), torch.stack(y_MLM).to(device), torch.stack(y_NSP).to(device)\n",
    "    \n",
    "    def _make_input(self, x0, x1):\n",
    "        return torch.cat([\n",
    "            torch.tensor([self.CLS]), \n",
    "            x0,\n",
    "            torch.tensor([self.SEP]), \n",
    "            x1,\n",
    "            torch.tensor([self.SEP])\n",
    "        ])\n",
    "    \n",
    "    def _mask(self, x):\n",
    "        for i, v in enumerate(x):\n",
    "            if random() < 0.15:\n",
    "                r2 = random()\n",
    "                if r2 < 0.80:\n",
    "                    x[i] = data_loader.MASK\n",
    "                elif 0.80 <= r2 < 0.90:\n",
    "                    x[i] = int(random() * (self.max_vocab_size - 100))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c2612558-9301-434e-baf6-f32721af4ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocabulary size=2213, compression ratio=0.4458684554516162\n",
      "train_data.shape=torch.Size([397855]), val_data.shape=torch.Size([99459])\n",
      "new tokens: 2215, 2216, 2217, 2218\n"
     ]
    }
   ],
   "source": [
    "data_loader = BERTDataLoader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0dc9bfc4-e0b5-45ef-921b-cfba202dd917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TEST PASSED same sentence\n",
      "2 TEST PASSED same sentence\n",
      "3 TEST PASSED same sentence\n"
     ]
    }
   ],
   "source": [
    "x, y_MLM, y_NSP = data_loader.next_batch(device=device, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b334a767-8352-41ab-9482-d586b336b176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 13]), torch.Size([6, 13]), torch.Size([6]))"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y_MLM.shape, y_NSP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ba935-4a40-4601-a06e-7018ba095b6c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "604c92b2-feb4-4e41-b0ed-8b4e3deb7bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BERTConfig:\n",
    "    BERT_batch_size = 6\n",
    "    batch_size = BERT_batch_size * 2\n",
    "    block_size = 5\n",
    "    embedding_size = 16\n",
    "    vocab_size = 2220 # new tokens: 2215, 2216, 2217, 2218 from dataloader\n",
    "    input_size = 2 * block_size + 3\n",
    "    \n",
    "config = BERTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c1279ca3-c9c7-4b04-aa14-1ccb259f929c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4d142907-07e2-4e41-a3a3-bcf771d38e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_x1_x2(x, config):\n",
    "    return x[:, 1:1+config.block_size], x[:, 1+config.block_size+1:-1]\n",
    "\n",
    "class InputRepresentation(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size, config.embedding_size)\n",
    "        self.segment_embeddings = nn.Embedding(2, config.embedding_size)\n",
    "        self.position_embeddings = nn.Embedding(config.input_size + 1, config.embedding_size)\n",
    "        self.register_buffer('segment_index', \n",
    "                             torch.tensor(sum([\n",
    "                                 [0] * (config.block_size + 1), \n",
    "                                 [0], \n",
    "                                 [1] * (config.block_size + 1)], [])))\n",
    "        self.register_buffer('position_index', \n",
    "                             torch.arange(config.input_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        token_embeddings = self.token_embeddings(x)\n",
    "        segment_embeddings = self.segment_embeddings(self.segment_index)\n",
    "        position_embeddings = self.position_embeddings(self.position_index)\n",
    "        x = position_embeddings + token_embeddings + segment_embeddings\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "27f3ddb7-0848-45df-bdc3-701e80eeb1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputRepresentation(\n",
       "  (token_embeddings): Embedding(2220, 16)\n",
       "  (segment_embeddings): Embedding(2, 16)\n",
       "  (position_embeddings): Embedding(14, 16)\n",
       ")"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = InputRepresentation(config)\n",
    "input_embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "0f8bf1f8-465b-427f-865c-921ff89cb650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 13, 16])"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = input_embeddings(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16b2bb-163b-4fbb-8af1-f04e14c738b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
