{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5c225d-637d-42bb-b4a9-098bd27cb486",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-22 04:09:17--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-02-22 04:09:17 (146 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf443f0c-36e2-4ec0-b591-897d434a881e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your notebook's working directory is set such that ../llm-tokenizer is reachable:\n",
    "tokenizer_dir = os.path.abspath(os.path.join(os.getcwd(), '../llm-tokenizer'))\n",
    "if tokenizer_dir not in sys.path:\n",
    "    sys.path.insert(0, tokenizer_dir)\n",
    "\n",
    "import BPETokenizer  # Now you should be able to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22820cf2-f6be-4a2b-84cb-d7dc0cd42490",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device index: 0\n",
      "Running on GPU: NVIDIA RTX A6000\n",
      "GPU properties:\n",
      "  - Compute Capability: 8.6\n",
      "  - Total Memory: 47.54 GB\n",
      "  - Multiprocessor Count: 84\n",
      "  - Max Threads per Multiprocessor: 1536\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from random import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    current_device = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(current_device)\n",
    "    device_props = torch.cuda.get_device_properties(current_device)\n",
    "    memory_summary = torch.cuda.memory_summary(device=current_device, abbreviated=True)\n",
    "    \n",
    "    print(\"Current device index:\", current_device)\n",
    "    print(\"Running on GPU:\", device_name)\n",
    "    print(\"GPU properties:\")\n",
    "    print(\"  - Compute Capability:\", f\"{device_props.major}.{device_props.minor}\")\n",
    "    print(\"  - Total Memory:\", f\"{device_props.total_memory / (1024**3):.2f} GB\")\n",
    "    print(\"  - Multiprocessor Count:\", device_props.multi_processor_count)\n",
    "    print(\"  - Max Threads per Multiprocessor:\", device_props.max_threads_per_multi_processor)\n",
    "else:\n",
    "    print(\"CUDA is not available, running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacea303-4d3d-429d-b2ab-bf2debdb5218",
   "metadata": {},
   "source": [
    "# Pretraining Data - GPT Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b04823-54d4-47dd-a2f3-fc99240d0f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"next token prediction DataLoader used for GPT like models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        len(text)\n",
    "\n",
    "        self.tokenizer = BPETokenizer.Tokenizer(text, encoding_vocab_size=2000, raw_tokens=False)\n",
    "        self.tokenizer.load_from_file()\n",
    "        encoded_dataset = self.tokenizer.encode(text, raw_tokens=False)\n",
    "        print(f\"max vocabulary size={max(encoded_dataset)}, compression ratio={len(encoded_dataset) / len(text)}\")\n",
    "        split = int(len(encoded_dataset) * 0.80)\n",
    "        self.train_data =  torch.tensor(encoded_dataset[:split])\n",
    "        self.val_data = torch.tensor(encoded_dataset[split+config.block_size:])\n",
    "        print(f\"train_data.shape={self.train_data.shape}, val_data.shape={self.val_data.shape}\")\n",
    "        \n",
    "        self.train_data_ix = 0\n",
    "        self.val_data_ix = 0\n",
    "        self.batch_step = self.config.batch_size * self.config.block_size \n",
    "        \n",
    "    def next_batch(self, mode=\"train\", device=device):\n",
    "        \"\"\" mode=[\"train\", \"eval\"] \"\"\"\n",
    "        if mode == \"train\":\n",
    "            x, y = self._next_batch_train()\n",
    "        else:\n",
    "            x, y = self._next_batch_eval()\n",
    "        if device:\n",
    "            return x.to(device), y.to(device)\n",
    "        return x, y\n",
    "    \n",
    "    def _next_batch_train(self):\n",
    "        \n",
    "        data = self.train_data\n",
    "        ix = int(random() * (len(data) - 2*self.batch_step))\n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.train_data_ix += self.batch_step \n",
    "        if self.train_data_ix + self.batch_step + 1 > len(self.train_data):\n",
    "            self.train_data_ix = 0\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def _next_batch_eval(self):\n",
    "        \n",
    "        data = self.train_data\n",
    "        ix = int(random() * (len(data) - 2*self.batch_step))\n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.val_data_ix += self.batch_step \n",
    "        if self.val_data_ix + self.batch_step + 1 > len(self.val_data):\n",
    "            self.val_data_ix = 0\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72adc4f3-2640-4a05-9969-079806cbcb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BERTConfig:\n",
    "    BERT_batch_size = 6\n",
    "    batch_size = BERT_batch_size * 2\n",
    "    block_size = 5\n",
    "    \n",
    "config = BERTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83c2b8ed-11e0-485e-9bcc-b28bcd8a0471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocabulary size=2213, compression ratio=0.4458684554516162\n",
      "train_data.shape=torch.Size([397855]), val_data.shape=torch.Size([99459])\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(config)\n",
    "x, y = data_loader.next_batch(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79332896-fd09-4b61-999b-932d87e2beb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 5]), torch.Size([12, 5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0436274-8a8b-4ff6-bb04-061f1d89e734",
   "metadata": {},
   "source": [
    "# Pretraining Data - BERT Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "364c0fdd-5ba2-4b1b-a4c6-8b727c14a2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataLoader(DataLoader):\n",
    "    \"\"\"data loader for BERT-like MLM + NSP loss\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.max_vocab_size = max(self.tokenizer.encoding_map.values())\n",
    "        self.CLS =self.max_vocab_size + 1\n",
    "        self.SEP = self.CLS + 1\n",
    "        self.MASK = self.SEP + 1\n",
    "        print(f\"new tokens: {self.max_vocab_size}, {self.CLS}, {self.SEP}, {self.MASK}\")\n",
    "        \n",
    "    def next_batch(self, device=device, test=False):\n",
    "        \"\"\"return x, y for Masked Language Model (MLM), MLM loss mask, y for Next Sentence Prediction\"\"\"\n",
    "        _x, _ = super().next_batch(device=None)\n",
    "        x, y_MLM, ix_MLM, y_NSP = [], [], [], []\n",
    "        assert len(_x) % 2 == 0, \"BERTDataLoader batch size should be % 2 == 0\"\n",
    "        for ix in range(int(len(_x) / 2)): \n",
    "            x0 = _x[ix].clone()\n",
    "            if random() < 0.5:\n",
    "                x1 = _x[ix+1].clone()\n",
    "                y_NSP.append(torch.tensor(1))\n",
    "            else:\n",
    "                __x, _ = super().next_batch(device=None)\n",
    "                x1 = __x[0].clone()\n",
    "                y_NSP.append(torch.tensor(0))\n",
    "            y_MLM.append(self._make_input(x0, x1))\n",
    "            x0, ix0 = self._mask(x0)\n",
    "            x1, ix1 = self._mask(x1)\n",
    "            x.append(self._make_input(x0, x1))\n",
    "            ix_MLM.append(torch.cat([\n",
    "                torch.tensor([0]), \n",
    "                ix0,\n",
    "                torch.tensor([0]), \n",
    "                ix1,\n",
    "                torch.tensor([0])\n",
    "                ]))\n",
    "            \n",
    "        if test:\n",
    "            for i, xx in enumerate(x):\n",
    "                if y_NSP[i] == 1:\n",
    "                    a, b = y_MLM[i][1:1+BERTConfig.block_size], _x[i]\n",
    "                    assert (a == b).all(), (a, b)\n",
    "                    a, b = y_MLM[i][1+BERTConfig.block_size+1:1+2*BERTConfig.block_size+1], _x[i+1]\n",
    "                    assert (a == b).all(), (a, b)\n",
    "                    print(f\"{i} TEST PASSED same sentence\")\n",
    "                    \n",
    "        # turn indexes of MLM into a average loss mask\n",
    "        ix_MLM = torch.stack(ix_MLM).to(device)\n",
    "        ix_MLM = (ix_MLM / ix_MLM.sum()).nan_to_num(0.0)\n",
    "            \n",
    "        return (\n",
    "            torch.stack(x).to(device), \n",
    "            torch.stack(y_MLM).to(device), \n",
    "            ix_MLM, \n",
    "            torch.stack(y_NSP).to(device)\n",
    "        )\n",
    "    \n",
    "    def _make_input(self, x0, x1):\n",
    "        return torch.cat([\n",
    "            torch.tensor([self.CLS]), \n",
    "            x0,\n",
    "            torch.tensor([self.SEP]), \n",
    "            x1,\n",
    "            torch.tensor([self.SEP])\n",
    "        ])\n",
    "    \n",
    "    def _mask(self, x):\n",
    "        ix = []\n",
    "        for i, v in enumerate(x):\n",
    "            if random() < 0.15:\n",
    "                ix.append(torch.tensor(1))\n",
    "                r2 = random()\n",
    "                if r2 < 0.80:\n",
    "                    x[i] = self.MASK\n",
    "                elif 0.80 <= r2 < 0.90:\n",
    "                    x[i] = int(random() * (self.max_vocab_size - 100))\n",
    "            else: ix.append(torch.tensor(0))\n",
    "        return x, torch.tensor(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c2612558-9301-434e-baf6-f32721af4ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocabulary size=2213, compression ratio=0.4458684554516162\n",
      "train_data.shape=torch.Size([397855]), val_data.shape=torch.Size([99459])\n",
      "new tokens: 2215, 2216, 2217, 2218\n"
     ]
    }
   ],
   "source": [
    "data_loader = BERTDataLoader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0dc9bfc4-e0b5-45ef-921b-cfba202dd917",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TEST PASSED same sentence\n",
      "2 TEST PASSED same sentence\n",
      "4 TEST PASSED same sentence\n",
      "5 TEST PASSED same sentence\n"
     ]
    }
   ],
   "source": [
    "x, y_MLM, loss_mask_MLM, y_NSP = data_loader.next_batch(device=device, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ba935-4a40-4601-a06e-7018ba095b6c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "604c92b2-feb4-4e41-b0ed-8b4e3deb7bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BERTConfig:\n",
    "    # model is going to be (BERT_batch_size, input_size, embedding_size or hidden_layer_size)\n",
    "    BERT_batch_size = 6\n",
    "    batch_size = BERT_batch_size * 2\n",
    "    block_size = 5\n",
    "    embedding_size = 64\n",
    "    vocab_size = 2220 # new tokens: 2215, 2216, 2217, 2218 from dataloader\n",
    "    input_size = 2 * block_size + 3\n",
    "    hidden_layer_size = 256\n",
    "    attention_heads = 8\n",
    "    attention_size = embedding_size // attention_heads\n",
    "    \n",
    "config = BERTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1279ca3-c9c7-4b04-aa14-1ccb259f929c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d142907-07e2-4e41-a3a3-bcf771d38e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_x1_x2(x, config):\n",
    "    return x[:, 1:1+config.block_size], x[:, 1+config.block_size+1:-1]\n",
    "\n",
    "class InputRepresentation(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(config.vocab_size, config.embedding_size)\n",
    "        self.segment_embeddings = nn.Embedding(2, config.embedding_size)\n",
    "        self.position_embeddings = nn.Embedding(config.input_size + 1, config.embedding_size)\n",
    "        self.register_buffer('segment_index', \n",
    "                             torch.tensor(sum([\n",
    "                                 [0] * (config.block_size + 1), \n",
    "                                 [0], \n",
    "                                 [1] * (config.block_size + 1)], [])))\n",
    "        self.register_buffer('position_index', \n",
    "                             torch.arange(config.input_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        token_embeddings = self.token_embeddings(x)\n",
    "        segment_embeddings = self.segment_embeddings(self.segment_index)\n",
    "        position_embeddings = self.position_embeddings(self.position_index)\n",
    "        x = position_embeddings + token_embeddings + segment_embeddings\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27f3ddb7-0848-45df-bdc3-701e80eeb1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputRepresentation(\n",
       "  (token_embeddings): Embedding(2220, 64)\n",
       "  (segment_embeddings): Embedding(2, 64)\n",
       "  (position_embeddings): Embedding(14, 64)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = InputRepresentation(config)\n",
    "input_embeddings.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd16b2bb-163b-4fbb-8af1-f04e14c738b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(config.embedding_size, config.attention_size)\n",
    "        self.query = nn.Linear(config.embedding_size, config.attention_size)\n",
    "        self.value = nn.Linear(config.embedding_size, config.attention_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        key = self.key(x)\n",
    "        query = self.query(x)\n",
    "        attention = F.softmax(k @ q.transpose(1, 2), dim=2)\n",
    "        value = self.value(x)\n",
    "        return attention @ value\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttention(config) for _ in range(config.attention_heads)])\n",
    "        self.linear = nn.Linear(config.embedding_size, config.embedding_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        heads = []\n",
    "        for head in self.heads:\n",
    "            heads.append(head(x))\n",
    "        x = torch.cat(heads, dim=2)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54575c62-8958-47cc-82c4-0252caa16be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (heads): ModuleList(\n",
       "    (0-7): 8 x SelfAttention(\n",
       "      (key): Linear(in_features=64, out_features=8, bias=True)\n",
       "      (query): Linear(in_features=64, out_features=8, bias=True)\n",
       "      (value): Linear(in_features=64, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = SelfAttention(config)\n",
    "attention.to(device)\n",
    "\n",
    "attention = MultiHeadAttention(config)\n",
    "attention.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d9c67cff-8e77-4d29-98ed-613dfd9739b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.input_representation = InputRepresentation(config)\n",
    "        self.multi_head_attention = MultiHeadAttention(config)\n",
    "        \n",
    "        self.MLM_output = nn.Linear(config.embedding_size, config.vocab_size)\n",
    "        self.NSP_output = nn.Linear(config.embedding_size, 1)\n",
    "        \n",
    "    def forward(self, x, y_NSP=None, y_MLM=None, loss_mask_MLM=None):\n",
    "        \"\"\"return (pred_NSP, logits_MSM, loss_NSP, loss_MLM)\"\"\"\n",
    "        x = self.input_representation(x)\n",
    "        pred_NSP = F.sigmoid(self.NSP_output(x[:, 0, :]))\n",
    "        logits_MSM = self.MLM_output(x)\n",
    "        \n",
    "        loss_NSP, loss_MLM = None, None\n",
    "        if y_NSP is not None:\n",
    "            loss_NSP = F.binary_cross_entropy(pred_NSP.view(-1), y_NSP.to(torch.float))\n",
    "            \n",
    "        if y_MLM is not None and loss_mask_MLM is not None:\n",
    "            loss_MLM = F.cross_entropy(\n",
    "                logits_MSM.reshape(config.BERT_batch_size * config.input_size, -1), \n",
    "                y_MLM.reshape(-1),\n",
    "                reduction='none')\n",
    "            loss_MLM = (loss_MLM * loss_mask_MLM.view(-1)).sum()\n",
    "        \n",
    "        \n",
    "        return pred_NSP, logits_MSM, loss_NSP, loss_MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "623a03dd-0569-4157-a5b9-c15d2a39031f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (input_representation): InputRepresentation(\n",
       "    (token_embeddings): Embedding(2220, 64)\n",
       "    (segment_embeddings): Embedding(2, 64)\n",
       "    (position_embeddings): Embedding(14, 64)\n",
       "  )\n",
       "  (multi_head_attention): MultiHeadAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-7): 8 x SelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=8, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (MLM_output): Linear(in_features=64, out_features=2220, bias=True)\n",
       "  (NSP_output): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERT(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "77035940-cd66-46b1-9687-21331fe8526b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y_MLM, loss_mask_MLM, y_NSP = data_loader.next_batch(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31497646-6c95-4f06-a16c-d3f137403afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_NSP, logits_MSM, loss_NSP, loss_MLM = model(x, y_NSP=y_NSP, y_MLM=y_MLM, loss_mask_MLM=loss_mask_MLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "82f17cf8-540b-48ce-a7cf-9b6ba4e30a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.4182, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor(0.6389, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_MLM, loss_NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72f8f1-a7a1-4998-b15c-45dd826ca067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
