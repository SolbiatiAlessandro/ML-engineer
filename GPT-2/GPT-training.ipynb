{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b8a4d6-d6f6-47d2-912a-5a7652b76d7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pretraining Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b63c04-c480-4b7c-9776-2aa43a77fd82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57d750f-cbbc-4bd9-a95c-c09e1c5ee871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your notebook's working directory is set such that ../llm-tokenizer is reachable:\n",
    "tokenizer_dir = os.path.abspath(os.path.join(os.getcwd(), '../llm-tokenizer'))\n",
    "if tokenizer_dir not in sys.path:\n",
    "    sys.path.insert(0, tokenizer_dir)\n",
    "\n",
    "import BPETokenizer  # Now you should be able to import it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b4d03c-7dfd-4c44-8fcb-89a19a03d364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5beac83-f678-414e-a318-7acdca821f24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 21 08:21:18 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   44C    P8    15W / 140W |      1MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe1d6bb-4262-455f-841a-48d78bac6e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from GPT import GPT, GPTConfig\n",
    "\n",
    "config = GPTConfig\n",
    "config.batch_size = 1024\n",
    "config.block_size = 64\n",
    "config.epochs = 10000\n",
    "config.validation_frequency = 20\n",
    "config.validation_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00e050e-4c02-4768-b0dd-bf718cdf001d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "        with open('input.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "        len(text)\n",
    "\n",
    "        tokenizer = BPETokenizer.Tokenizer(text, encoding_vocab_size=2000, raw_tokens=False)\n",
    "        tokenizer.load_from_file()\n",
    "        encoded_dataset = tokenizer.encode(text, raw_tokens=False)\n",
    "        print(f\"max vocabulary size={max(encoded_dataset)}, compression ratio={len(encoded_dataset) / len(text)}\")\n",
    "        split = int(len(encoded_dataset) * 0.80)\n",
    "        self.train_data =  torch.tensor(encoded_dataset[:split])\n",
    "        self.val_data = torch.tensor(encoded_dataset[split+config.block_size:])\n",
    "        print(f\"train_data.shape={self.train_data.shape}, val_data.shape={self.val_data.shape}\")\n",
    "        \n",
    "        self.train_data_ix = 0\n",
    "        self.val_data_ix = 0\n",
    "        self.batch_step = self.config.batch_size * self.config.block_size \n",
    "        \n",
    "    def next_batch(self, mode=\"train\", device=device):\n",
    "        \"\"\" mode=[\"train\", \"eval\"] \"\"\"\n",
    "        if mode == \"train\":\n",
    "            x, y = self._next_batch_train()\n",
    "        else:\n",
    "            x, y = self._next_batch_eval()\n",
    "        return x.to(device), y.to(device)\n",
    "    \n",
    "    def _next_batch_train(self):\n",
    "        \n",
    "        data = self.train_data\n",
    "        ix = self.train_data_ix \n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.train_data_ix += self.batch_step \n",
    "        if self.train_data_ix + self.batch_step + 1 > len(self.train_data):\n",
    "            self.train_data_ix = 0\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def _next_batch_eval(self):\n",
    "        \n",
    "        data = self.val_data\n",
    "        ix = self.val_data_ix \n",
    "        \n",
    "        buf = data[ix:ix+self.batch_step + 1]     \n",
    "        x = buf[:-1].view(self.config.batch_size, self.config.block_size)\n",
    "        y = buf[1:].view(self.config.batch_size, self.config.block_size)\n",
    "        \n",
    "        self.val_data_ix += self.batch_step \n",
    "        if self.val_data_ix + self.batch_step + 1 > len(self.val_data):\n",
    "            self.val_data_ix = 0\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49151b5-fae7-423c-b454-38e1e8e8b199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max vocabulary size=2213, compression ratio=0.4458684554516162\n",
      "train_data.shape=torch.Size([397855]), val_data.shape=torch.Size([99400])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  70,  299,  296,  ...,  275,  267,   82],\n",
       "         [ 280,  403, 1410,  ...,   70,  299,  296],\n",
       "         [  32, 1709,   76,  ...,  274,  260, 1709],\n",
       "         ...,\n",
       "         [  79,  491, 2051,  ...,  467,  394,  360],\n",
       "         [ 595,  104,  549,  ...,  594,  288,  316],\n",
       "         [ 104,  290,  320,  ...,  335,  424,   32]], device='cuda:0'),\n",
       " tensor([[ 299,  296,   32,  ...,  267,   82,  280],\n",
       "         [ 403, 1410,  100,  ...,  299,  296,   32],\n",
       "         [1709,   76,  453,  ...,  260, 1709, 1045],\n",
       "         ...,\n",
       "         [ 491, 2051,  856,  ...,  394,  360,  595],\n",
       "         [ 104,  549,  774,  ...,  288,  316,  104],\n",
       "         [ 290,  320,  359,  ...,  424,   32,   82]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(config)\n",
    "data_loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e956f6-76c0-492a-a4d9-d04c3754c6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 64]), torch.Size([1024, 64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_loader.next_batch()\n",
    "x1, y = data_loader.next_batch()\n",
    "assert x[0][0] != x1[0][0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ede0d4-a12f-4ab6-8ad0-8fcdeae094e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mnext_batch(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m x1, y \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mnext_batch(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m x1[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, y = data_loader.next_batch(mode=\"eval\")\n",
    "x1, y = data_loader.next_batch(mode=\"eval\")\n",
    "assert x[0][0] != x1[0][0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d28f3-fd93-45f0-9106-daa6f927226b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de32b49c-1bc7-4151-b6b4-1ec5e02398e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape=torch.Size([1024, 64]), device=cuda:0\n",
      "y: shape=torch.Size([1024, 64]), device=cuda:0\n",
      "x1: shape=torch.Size([1024, 64]), device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "#del X_tr\n",
    "#del y_tr\n",
    "\n",
    "l = locals().items()\n",
    "for name, obj in l:\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "            print(f\"{name}: shape={obj.shape}, device={obj.device}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d03247c-3825-4f42-8584-030401090cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 21 08:23:10 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   45C    P2    37W / 140W |    191MiB / 16376MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee70179-e678-4172-bc4f-1535dfa15fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162299904\n"
     ]
    }
   ],
   "source": [
    "model = GPT(config)\n",
    "model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd0a029b-2b85-444d-82b7-9e527fa203dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 15.73 GiB of which 57.12 MiB is free. Process 3475790 has 15.67 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 192.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      7\u001b[0m X, y \u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mnext_batch()\n\u001b[0;32m----> 8\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits\u001b[38;5;241m.\u001b[39mview(bb, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39mview(bb))\n\u001b[1;32m     10\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/ML-system-design/GPT-2/GPT.py:126\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    124\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwpe(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, T, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mh:\n\u001b[0;32m--> 126\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mln_f(x)\n\u001b[1;32m    128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/ML-system-design/GPT-2/GPT.py:102\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 102\u001b[0m     attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m attention \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m    104\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(x))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/ML-system-design/GPT-2/GPT.py:54\u001b[0m, in \u001b[0;36mMultiHeadedMaskedSelfAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m attention \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# this could be slow cause we are creating mask every time\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m masked_attention \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtril\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m     61\u001b[0m     B, \n\u001b[1;32m     62\u001b[0m     T, \n\u001b[1;32m     63\u001b[0m     config\u001b[38;5;241m.\u001b[39mn_head,\n\u001b[1;32m     64\u001b[0m     config\u001b[38;5;241m.\u001b[39mn_embd \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mn_head\n\u001b[1;32m     65\u001b[0m )\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m masked_attention \u001b[38;5;241m@\u001b[39m v\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacty of 15.73 GiB of which 57.12 MiB is free. Process 3475790 has 15.67 GiB memory in use. Of the allocated memory 15.29 GiB is allocated by PyTorch, and 192.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)\n",
    "# train_losses, val_losses = [], []\n",
    "bb = config.batch_size * config.block_size\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    optimizer.zero_grad()\n",
    "    X, y = data_loader.next_batch()\n",
    "    logits = model(X)\n",
    "    train_loss = F.cross_entropy(logits.view(bb, -1), y.view(bb))\n",
    "    train_losses.append(train_loss.item())\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % config.validation_frequency == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_losses = []\n",
    "            for _ in range(config.validation_epochs):\n",
    "                X, y = data_loader.next_batch(mode=\"eval\")\n",
    "                logits = model(X)\n",
    "                val_loss = F.cross_entropy(logits.view(bb, -1), y.view(bb))\n",
    "                epoch_val_losses.append(val_loss)\n",
    "            val_loss = sum(epoch_val_losses) / len(epoch_val_losses)\n",
    "            model.train()\n",
    "    \n",
    "    \n",
    "  \n",
    "            val_losses.append(val_loss)\n",
    "            print(f\"[{epoch}/{config.epochs}] train_loss={train_loss.item():.2f}, val_loss={val_loss:.2f}\")\n",
    "\n",
    "# [880/10000] train_loss=3.59, val_loss=4.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "056f6d8c-64b2-4b0e-9957-27008e1760ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gap = 4\n",
    "plot_size = gap * len(val_losses)\n",
    "val_losses = [t.cpu() for t in val_losses]\n",
    "clip = (len(train_losses) // plot_size) * plot_size\n",
    "\n",
    "plt.plot(torch.tensor(train_losses[:clip]).view(plot_size, - 1).mean(1))\n",
    "plt.plot([i * gap for i, _ in enumerate(val_losses)], val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c371c-75bf-480f-acf1-4e3b38f2152e",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a2af6a63-18fd-41fd-8bf2-e62b44dbe522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32]], device='cuda:0')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \" \"\n",
    "tokens = tokenizer.encode(prompt, raw_tokens=False)\n",
    "tokens\n",
    "model.eval()\n",
    "x = torch.tensor(tokens[:config.block_size], device=device).view(1, -1)\n",
    "x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "16a90187-2b9e-4294-b80d-0bcd030dd663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " unes of bratry arms they guk'd, in.\n",
      "\n",
      "KING HENRY VI:\n",
      "Can, how lorims good!\n",
      "\n",
      "Second now, man:\n",
      "First nothing, my lord by thy seve thore.\n",
      "'Tis true that hason'd is be to dide is kinlnelk tharideed?\n",
      "\n",
      "LEONTES:\n",
      "Lest are your pas it: but I excesterntak to hese should all orself them!\n",
      "I murp, by SON:\n",
      "A more before his\n",
      "country nor say'd flame, I will heard to vain!\n",
      "You former grace, deempes widow his down when never shere,\n",
      "If ithere is chan with is it fiel me,\n",
      "Make bellaining the coward.\n",
      "\n",
      "Pethle sindom you hontal king touch\n",
      "And memust and a tion the is over buthow\n",
      "Hereforry restrist him. I kneet\n",
      "By hear's life,\n",
      "As the princence it fling-would liberse that you and and stubirst thee?\n",
      "\n",
      "LORY:\n",
      "O, now Clow excus, in blead?\n",
      "\n",
      "Were my hese birst now a which have thou not for here?\n",
      "\n",
      "Pold now it Call missue,\n",
      "Alauding.\n",
      "\n",
      "LORICHARD III:\n",
      "That a gentlemarsless plus, what why, that I welse Gontain the mayer the worl are dir should te thee bider.\n",
      "\n",
      "A four generall, my so Feather:\n",
      "But thou shalt not so.\n",
      "What non, I'll this fame on here: da.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_decode = x.tolist()[0]\n",
    "for _ in range(500):\n",
    "    \n",
    "    x = x[-config.block_size:]\n",
    "\n",
    "    logits = model(x.view(1, -1))\n",
    "    \n",
    "    new_token = torch.multinomial(F.softmax(logits[0, -1, :], dim=0),  1)\n",
    "    v, ixs = logits[0, -1, :].topk(50)\n",
    "    ix = torch.multinomial(F.softmax(v, dim=0), 1)\n",
    "    new_token = ixs[ix]\n",
    "    to_decode.append(new_token.view(-1).item())\n",
    "    x = torch.cat([x.view(-1), new_token])\n",
    "\n",
    "print(tokenizer.decode(to_decode, raw_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9f8893b1-1fc8-4096-a12d-cafe6f23046b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"First Citizen:\"\n",
    "tokens = tokenizer.encode(prompt, raw_tokens=False)\n",
    "tokenizer.decode(tokens, raw_tokens=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8258e-794d-4582-aaaf-4cef56888278",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "955faa6b-d842-4457-a04c-1bbd50b73f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "79b5b0f7-5e55-4a65-ac36-dc1ac0ffe9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24737, 64]), torch.Size([24737, 64]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "18601586-9b54-403f-80a1-dc2b64e9e686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples = 20\n",
    "y_pred = model(X_val[:samples])\n",
    "y_pred = torch.argmax(F.softmax(y_pred, dim=2), dim=2)\n",
    "y_val = y_val[:samples]\n",
    "val, counts = torch.unique((y_pred == y_val).view(-1), return_counts=True)\n",
    "assert val[1] == True\n",
    "print(f\"({samples * config.batch_size} samples) precision={counts[1] / (counts[0] + counts[1]).item():.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ca80803e-36ae-448d-a742-231512242f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aa384de8-b029-48b3-8331-71f72180c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "64429312-ec31-4b78-9692-0bdc0a5687d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "099d2e8e-3eab-4e58-aeeb-2ad653196781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640 samples) precision=0.226%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4bb2d-7d63-41df-8c32-19ab35ec8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (640 samples) precision=0.226%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
